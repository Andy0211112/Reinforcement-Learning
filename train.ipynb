{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc683844-6b34-44fa-add6-5b006cba1060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pipreqs: not found\n"
     ]
    }
   ],
   "source": [
    "!pipreqs /home/nthuuser/下載/Andy/train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e84cd9f-0616-46b1-8f15-780b56fc6fa9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chess\n",
    "import chess.svg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from collections import deque\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "from IPython.display import SVG, display\n",
    "import ftplib\n",
    "import hashlib\n",
    "import json\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e6654ff-c2f6-4a29-b45f-e6466608d357",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pieces_order = 'KQRBNPkqrbnp'  # 12x8x8\n",
    "castling_order = 'KQkq'\n",
    "ind = {pieces_order[i]: i for i in range(12)}\n",
    "\n",
    "def alg_to_coord(alg):\n",
    "    rank = 8 - int(alg[1])        # 0-7\n",
    "    file = ord(alg[0]) - ord('a')  # 0-7\n",
    "    return rank, file\n",
    "\n",
    "\n",
    "def coord_to_alg(coord):\n",
    "    letter = chr(ord('a') + coord[1])\n",
    "    number = str(8 - coord[0])\n",
    "    return letter + number\n",
    "\n",
    "\n",
    "def to_planes(fen):\n",
    "    board_state = replace_tags_board(fen)\n",
    "    pieces_both = np.zeros(shape=(12, 8, 8), dtype=np.float32)\n",
    "    for rank in range(8):\n",
    "        for file in range(8):\n",
    "            v = board_state[rank * 8 + file]\n",
    "            if v.isalpha():\n",
    "                pieces_both[ind[v]][rank][file] = 1\n",
    "    assert pieces_both.shape == (12, 8, 8)\n",
    "    return pieces_both\n",
    "\n",
    "\n",
    "def replace_tags_board(board_san):\n",
    "    board_san = board_san.split(\" \")[0]\n",
    "    board_san = board_san.replace(\"2\", \"11\")\n",
    "    board_san = board_san.replace(\"3\", \"111\")\n",
    "    board_san = board_san.replace(\"4\", \"1111\")\n",
    "    board_san = board_san.replace(\"5\", \"11111\")\n",
    "    board_san = board_san.replace(\"6\", \"111111\")\n",
    "    board_san = board_san.replace(\"7\", \"1111111\")\n",
    "    board_san = board_san.replace(\"8\", \"11111111\")\n",
    "    return board_san.replace(\"/\", \"\")\n",
    "\n",
    "\n",
    "def is_black_turn(fen):\n",
    "    return fen.split(\" \")[1] == 'b'\n",
    "\n",
    "def check_current_planes(realfen, planes):\n",
    "    cur = planes[0:12]\n",
    "    assert cur.shape == (12, 8, 8)\n",
    "    fakefen = [\"1\"] * 64\n",
    "    for i in range(12):\n",
    "        for rank in range(8):\n",
    "            for file in range(8):\n",
    "                if cur[i][rank][file] == 1:\n",
    "                    assert fakefen[rank * 8 + file] == '1'\n",
    "                    fakefen[rank * 8 + file] = pieces_order[i]\n",
    "\n",
    "    castling = planes[12:16]\n",
    "    fiftymove = planes[16][0][0]\n",
    "    ep = planes[17]\n",
    "\n",
    "    castlingstring = \"\"\n",
    "    for i in range(4):\n",
    "        if castling[i][0][0] == 1:\n",
    "            castlingstring += castling_order[i]\n",
    "\n",
    "    if len(castlingstring) == 0:\n",
    "        castlingstring = '-'\n",
    "\n",
    "    epstr = \"-\"\n",
    "    for rank in range(8):\n",
    "        for file in range(8):\n",
    "            if ep[rank][file] == 1:\n",
    "                epstr = coord_to_alg((rank, file))\n",
    "\n",
    "    # realfen = maybe_flip_fen(realfen, flip=is_black_turn(realfen))\n",
    "    realparts = realfen.split(' ')\n",
    "    assert realparts[1] == 'w'\n",
    "    assert realparts[2] == castlingstring\n",
    "    assert realparts[3] == epstr\n",
    "    assert int(realparts[4]) == fiftymove\n",
    "    # realparts[5] is the fifty-move clock, discard that\n",
    "    return \"\".join(fakefen) == replace_tags_board(realfen)\n",
    "\n",
    "\n",
    "def canon_input_planes(fen):\n",
    "    \"\"\"\n",
    "    :param fen:\n",
    "    :return : (18, 8, 8) representation of the game state\n",
    "    \"\"\"\n",
    "    fen = maybe_flip_fen(fen, is_black_turn(fen))\n",
    "    return all_input_planes(fen)\n",
    "\n",
    "\n",
    "def all_input_planes(fen):\n",
    "    current_aux_planes = aux_planes(fen)\n",
    "\n",
    "    history_both = to_planes(fen)\n",
    "\n",
    "    ret = np.vstack((history_both, current_aux_planes))\n",
    "    assert ret.shape == (18, 8, 8)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def maybe_flip_fen(fen, flip=False):\n",
    "    if not flip:\n",
    "        return fen\n",
    "    foo = fen.split(' ')\n",
    "    rows = foo[0].split('/')\n",
    "\n",
    "    def swapcase(a):\n",
    "        if a.isalpha():\n",
    "            return a.lower() if a.isupper() else a.upper()\n",
    "        return a\n",
    "\n",
    "    def swapall(aa):\n",
    "        return \"\".join([swapcase(a) for a in aa])\n",
    "    return \"/\".join([swapall(row) for row in reversed(rows)]) \\\n",
    "        + \" \" + ('w' if foo[1] == 'b' else 'b') \\\n",
    "        + \" \" + \"\".join(sorted(swapall(foo[2]))) \\\n",
    "        + \" \" + foo[3] + \" \" + foo[4] + \" \" + foo[5]\n",
    "\n",
    "\n",
    "def aux_planes(fen):\n",
    "    foo = fen.split(' ')\n",
    "\n",
    "    en_passant = np.zeros((8, 8), dtype=np.float32)\n",
    "    if foo[3] != '-':\n",
    "        eps = alg_to_coord(foo[3])\n",
    "        en_passant[eps[0]][eps[1]] = 1\n",
    "\n",
    "    fifty_move_count = int(foo[4])\n",
    "    fifty_move = np.full((8, 8), fifty_move_count, dtype=np.float32)\n",
    "\n",
    "    castling = foo[2]\n",
    "    auxiliary_planes = [np.full((8, 8), int('K' in castling), dtype=np.float32),\n",
    "                        np.full((8, 8), int('Q' in castling),\n",
    "                                dtype=np.float32),\n",
    "                        np.full((8, 8), int('k' in castling),\n",
    "                                dtype=np.float32),\n",
    "                        np.full((8, 8), int('q' in castling),\n",
    "                                dtype=np.float32),\n",
    "                        fifty_move,\n",
    "                        en_passant]\n",
    "\n",
    "    ret = np.asarray(auxiliary_planes, dtype=np.float32)\n",
    "    assert ret.shape == (6, 8, 8)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c94356-4ee6-478b-ae16-100d07fa6851",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from collections import deque\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "# dataset = deque(), deque(), deque()\n",
    "# data_dir = '/content/drive/MyDrive/Colab_Notebooks/rl_chess'\n",
    "model_dir = 'models'\n",
    "play_data_dir = 'stockfish_data'\n",
    "play_data_filename_tmpl = \"best_dataset_2_%s.json\"\n",
    "# \"%s.json\"\n",
    "\n",
    "def find_pgn_files(directory, pattern='*.pgn'):\n",
    "  dir_pattern = os.path.join(directory, pattern)\n",
    "  files = list(sorted(glob(dir_pattern)))\n",
    "  return files\n",
    "\n",
    "def read_game_data_from_file(path):\n",
    "  try:\n",
    "    with open(path, \"rt\") as f:\n",
    "        return json.load(f)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "def get_game_data_filenames(play_data_dir,play_data_filename_tmpl):\n",
    "  pattern = os.path.join(play_data_dir, play_data_filename_tmpl % \"*\")\n",
    "  files = list(sorted(glob(pattern)))\n",
    "  return files\n",
    "\n",
    "def testeval(fen, absolute=False) -> float:\n",
    "    # somehow it doesn't know how to keep its queen\n",
    "    piece_vals = {'K': 3, 'Q': 14, 'R': 5, 'B': 3.25, 'N': 3, 'P': 1}\n",
    "    ans = 0.0\n",
    "    tot = 0\n",
    "    for c in fen.split(' ')[0]:\n",
    "        if not c.isalpha():\n",
    "            continue\n",
    "\n",
    "        if c.isupper():\n",
    "            ans += piece_vals[c]\n",
    "            tot += piece_vals[c]\n",
    "        else:\n",
    "            ans -= piece_vals[c.upper()]\n",
    "            tot += piece_vals[c.upper()]\n",
    "    v = ans/tot\n",
    "    if not absolute and is_black_turn(fen):\n",
    "        v = -v\n",
    "    assert abs(v) < 1\n",
    "    return np.tanh(v * 3)  # arbitrary\n",
    "\n",
    "def create_uci_labels():\n",
    "    \"\"\"\n",
    "    Creates the labels for the universal chess interface into an array and returns them\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    labels_array = []\n",
    "    letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "    numbers = ['1', '2', '3', '4', '5', '6', '7', '8']\n",
    "    promoted_to = ['q', 'r', 'b', 'n']\n",
    "\n",
    "    for l1 in range(8):\n",
    "        for n1 in range(8):\n",
    "            destinations = [(t, n1) for t in range(8)] + \\\n",
    "                           [(l1, t) for t in range(8)] + \\\n",
    "                           [(l1 + t, n1 + t) for t in range(-7, 8)] + \\\n",
    "                           [(l1 + t, n1 - t) for t in range(-7, 8)] + \\\n",
    "                           [(l1 + a, n1 + b) for (a, b) in\n",
    "                            [(-2, -1), (-1, -2), (-2, 1), (1, -2), (2, -1), (-1, 2), (2, 1), (1, 2)]]\n",
    "            for (l2, n2) in destinations:\n",
    "                if (l1, n1) != (l2, n2) and l2 in range(8) and n2 in range(8):\n",
    "                    move = letters[l1] + numbers[n1] + \\\n",
    "                        letters[l2] + numbers[n2]\n",
    "                    labels_array.append(move)\n",
    "    for l1 in range(8):\n",
    "        l = letters[l1]\n",
    "        for p in promoted_to:\n",
    "            labels_array.append(l + '2' + l + '1' + p)\n",
    "            labels_array.append(l + '7' + l + '8' + p)\n",
    "            if l1 > 0:\n",
    "                l_l = letters[l1 - 1]\n",
    "                labels_array.append(l + '2' + l_l + '1' + p)\n",
    "                labels_array.append(l + '7' + l_l + '8' + p)\n",
    "            if l1 < 7:\n",
    "                l_r = letters[l1 + 1]\n",
    "                labels_array.append(l + '2' + l_r + '1' + p)\n",
    "                labels_array.append(l + '7' + l_r + '8' + p)\n",
    "    return labels_array\n",
    "\n",
    "def flipped_uci_labels():\n",
    "    \"\"\"\n",
    "    Seems to somehow transform the labels used for describing the universal chess interface format, putting\n",
    "    them into a returned list.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    def repl(x):\n",
    "        return \"\".join([(str(9 - int(a)) if a.isdigit() else a) for a in x])\n",
    "\n",
    "    return [repl(x) for x in create_uci_labels()]\n",
    "\n",
    "\n",
    "def flip_policy(pol):\n",
    "    \"\"\"\n",
    "    :param pol policy to flip:\n",
    "    :return: the policy, flipped (for switching between black and white it seems)\n",
    "    \"\"\"\n",
    "    return np.asarray([pol[ind] for ind in unflipped_index])\n",
    "\n",
    "\n",
    "def convert_to_cheating_data(data):\n",
    "    \"\"\"\n",
    "    :param data: format is SelfPlayWorker.buffer\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    state_list = []\n",
    "    policy_list = []\n",
    "    value_list = []\n",
    "    for state_fen, policy, value in data:\n",
    "\n",
    "        state_planes = canon_input_planes(state_fen)\n",
    "        policy = all_moves2index_dict[policy]\n",
    "        temp = np.zeros((1968,))\n",
    "        temp[policy] = 1\n",
    "        policy = temp\n",
    "        del temp\n",
    "        if is_black_turn(state_fen):\n",
    "            policy = flip_policy(policy)\n",
    "\n",
    "        # move_number = int(state_fen.split(' ')[5])\n",
    "        # # reduces the noise of the opening... plz train faster\n",
    "        # value_certainty = min(10, move_number)/10\n",
    "        # _value = value*value_certainty + testeval(state_fen, False)*(1-value_certainty)\n",
    "\n",
    "        state_list.append(state_planes)\n",
    "        policy_list.append(policy)\n",
    "        value_list.append(value)\n",
    "\n",
    "    return np.array(state_list, dtype=np.float32), np.array(policy_list, dtype=np.float32), np.array(value_list, dtype=np.float32)\n",
    "\n",
    "\n",
    "def load_data_from_file(filename):\n",
    "    data = read_game_data_from_file(filename)\n",
    "    return convert_to_cheating_data(data)\n",
    "\n",
    "\n",
    "labels = create_uci_labels()\n",
    "n_labels = int(len(labels))\n",
    "flipped_labels = flipped_uci_labels()\n",
    "unflipped_index = [labels.index(x) for x in flipped_labels]\n",
    "all_moves2index_dict = {move: i for i, move in enumerate(labels)}\n",
    "int_to_move = {v: k for k, v in all_moves2index_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7936a8e-cd96-4afb-86d3-5e3fe2a11b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.action_size = 8*8*73\n",
    "        self.conv1 = nn.Conv2d(18, 256, 5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = s.view(-1, 18, 8, 8)  # batch_size x channels x board_x x board_y\n",
    "        s = F.relu(self.bn1(self.conv1(s)))\n",
    "        return s\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inplanes=256, planes=256, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class OutBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OutBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(256, 4, kernel_size=1) # value head\n",
    "        self.bn = nn.BatchNorm2d(4)\n",
    "        self.fc1 = nn.Linear(8*8*4, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(256, 2, kernel_size=1) # policy head\n",
    "        self.bn1 = nn.BatchNorm2d(2)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.fc = nn.Linear(8*8*2, 1968)\n",
    "\n",
    "    def forward(self, s):\n",
    "        v = F.relu(self.bn(self.conv(s))) # value head\n",
    "        v = v.view(-1, 4*8*8)\n",
    "        v = F.relu(self.fc1(v))\n",
    "        v = F.tanh(self.fc2(v))\n",
    "\n",
    "        p = F.relu(self.bn1(self.conv1(s))) # policy head\n",
    "        p = p.view(-1, 2*8*8)\n",
    "        p = self.fc(p)\n",
    "        p = self.logsoftmax(p).exp()\n",
    "        return p, v\n",
    "\n",
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "        self.conv = ConvBlock()\n",
    "        for block in range(7):\n",
    "            setattr(self, f\"res_{block}\", ResBlock())\n",
    "        self.outblock = OutBlock()\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = self.conv(s)\n",
    "        for block in range(7):\n",
    "            s = getattr(self, f\"res_{block}\")(s)\n",
    "        return self.outblock(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c546bf5-1476-4f0f-9134-dd3b7a6f2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(state_ary, policy_ary, value_ary,batch_size = 128):\n",
    "  states = []\n",
    "  policies = []\n",
    "  values = []\n",
    "  n = state_ary.shape[0]\n",
    "  for i in range(n//batch_size):\n",
    "    states.append(torch.tensor(state_ary[i*batch_size:(i+1)*batch_size],dtype=torch.float32).to(device))\n",
    "    policies.append(torch.tensor(policy_ary[i*batch_size:(i+1)*batch_size],dtype=torch.float32).to(device))\n",
    "    values.append(torch.tensor(value_ary[i*batch_size:(i+1)*batch_size],dtype=torch.float32).to(device))\n",
    "  if n%batch_size != 0:\n",
    "    states.append(torch.tensor(state_ary[n//batch_size*batch_size:],dtype=torch.float32).to(device))\n",
    "    policies.append(torch.tensor(policy_ary[n//batch_size*batch_size:],dtype=torch.float32).to(device))\n",
    "    values.append(torch.tensor(value_ary[n//batch_size*batch_size:],dtype=torch.float32).to(device))\n",
    "  return states,policies,values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99cfab26-efb8-4d51-a1a7-962d6f62c200",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AlphaLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlphaLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_value, value, y_policy, policy):\n",
    "        value_error = (value - y_value) ** 2\n",
    "        policy_error = torch.sum((-policy * (1e-6 + y_policy.float()).float().log()), 1)\n",
    "        total_error = value_error.squeeze()*100 + policy_error\n",
    "        return total_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec969312-d2ec-4709-9f9b-7cdeaac93c41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChessAgent:\n",
    "    def __init__(self, name, device, path=None):\n",
    "        self.name = name\n",
    "        self.device = device\n",
    "        self.model = ChessNet().to(device)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001,weight_decay=1e-5)\n",
    "        self.criterion = AlphaLoss()\n",
    "\n",
    "        self.batch_size = 512\n",
    "        # self.train_size = 10000\n",
    "        self.tau_decay_rate = 0.99\n",
    "        if path:\n",
    "          self.load_model(model_dir,path)\n",
    "          self.model.to(device)\n",
    "        else:\n",
    "          pass\n",
    "\n",
    "    def load_model(self, dir, filename):\n",
    "        \"\"\"Load a model from disk.\"\"\"\n",
    "        if os.path.exists(os.path.join(dir,filename)):\n",
    "            # save_data = torch.load(os.path.join(dir,filename))\n",
    "            save_data = torch.load(os.path.join(dir,filename),map_location=device)\n",
    "            self.model.load_state_dict(save_data['model_state'])\n",
    "            print(f\"Model loaded from {filename}\")\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def save_model(self,dir, filename):\n",
    "        \"\"\"Save a model to disk.\"\"\"\n",
    "        save_data = {\n",
    "            'model_state': self.model.state_dict(),\n",
    "        }\n",
    "        path = os.path.join(dir,filename)\n",
    "        torch.save(save_data, path)\n",
    "        print(f\"Model saved to {path}\")\n",
    "\n",
    "    def choose_action(self, board,max_depth = 15,n_simulations=1000,mode = 'tree'):\n",
    "        \"\"\"Choose action by probability.\"\"\"\n",
    "        if mode == 'mcts':\n",
    "            n_move = int(board.fen().split(' ')[-1])\n",
    "            # move = mcts(board,self.model,n_simulations=n_simulations,temperature=(1/n_move)*5)\n",
    "            move = mcts(board,self.model,n_simulations=n_simulations,temperature = 1.0)\n",
    "            if move is None:\n",
    "                move = random.choice(list(board.legal_moves))\n",
    "            return move.uci()\n",
    "        elif mode == 'tree':\n",
    "            tree = MCTS(self.model, max_depth=max_depth)\n",
    "            root = tree.search(board, n_simulations=n_simulations)\n",
    "            move = root.best_action(temperature = 1.0)\n",
    "            if move is None:\n",
    "                move = random.choice(list(board.legal_moves))\n",
    "            return move.uci()\n",
    "\n",
    "    def apply_temperature(self, policy, turn):\n",
    "        \"\"\"\n",
    "        Applies a random fluctuation to probability of choosing various actions\n",
    "        :param policy: list of probabilities of taking each action\n",
    "        :param turn: number of turns that have occurred in the game so far\n",
    "        :return: policy, randomly perturbed based on the temperature. High temp = more perturbation. Low temp\n",
    "            = less.\n",
    "        \"\"\"\n",
    "        tau = np.power(self.tau_decay_rate, int(turn) + 1)\n",
    "        if tau < 0.1:\n",
    "            tau = 0\n",
    "        if tau == 0:\n",
    "            action = np.argmax(policy)\n",
    "            ret = np.zeros(1968)\n",
    "            ret[action] = 1.0\n",
    "            return ret\n",
    "        else:\n",
    "            ret = np.power(policy, 1/tau)\n",
    "            ret /= np.sum(ret)\n",
    "            return ret\n",
    "\n",
    "    def get_best_move(self, board):\n",
    "        policy,value = self.model(torch.FloatTensor(np.array(canon_input_planes(board.fen()))).to(device))\n",
    "        policy = policy.squeeze().cpu().detach().numpy()\n",
    "        value = value.squeeze().cpu().detach().numpy()\n",
    "        if is_black_turn(board.fen()):\n",
    "            policy = flip_policy(policy)\n",
    "        legal_moves = list(board.legal_moves)\n",
    "        legal_moves_uci = [move.uci() for move in legal_moves]\n",
    "        sorted_indices = np.argsort(policy)[::-1]\n",
    "        for move_index in sorted_indices:\n",
    "            move = int_to_move[move_index]\n",
    "            if move in legal_moves_uci:\n",
    "                return move\n",
    "        return None\n",
    "# agent = ChessAgent('test',device,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40ccd1b-f959-4bbe-be19-049f9887c178",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_from_data(agent):\n",
    "  filenames = get_game_data_filenames(play_data_dir,play_data_filename_tmpl)\n",
    "  filenames = filenames\n",
    "  print(filenames)\n",
    "  print(len(filenames))\n",
    "  epochs = 50\n",
    "  # agent = self.white_agent\n",
    "  steps = 0\n",
    "  batch_size = 2048\n",
    "  print(f'Training agent {agent.name}')\n",
    "  while len(filenames)>0:\n",
    "    states,policies,values=([],[],[])\n",
    "    for _ in range(10):\n",
    "      if not filenames:\n",
    "        break\n",
    "      filename = filenames.pop()\n",
    "      print(f'load data from {filename}')\n",
    "      state_ary, policy_ary, value_ary = load_data_from_file(filename)\n",
    "\n",
    "      temp = dataloader(state_ary, policy_ary, value_ary,batch_size)\n",
    "      states,policies,values = states+temp[0],policies+temp[1],values+temp[2]\n",
    "      del temp, state_ary, policy_ary, value_ary\n",
    "    print(f'num_data {len(values)}')\n",
    "    for epoch in range(epochs):\n",
    "      running_loss=0\n",
    "      for state,policy,value in zip(states,policies,values):\n",
    "        # print(state.size(),policy.size(),value.size())\n",
    "\n",
    "        predicted_policies, predicted_values = agent.model(state)\n",
    "        # print(predicted_values[-1],value[-1])\n",
    "        # print(predicted_policies.size(),predicted_values.size())\n",
    "\n",
    "        loss = agent.criterion(predicted_values, value, predicted_policies, policy)\n",
    "\n",
    "        agent.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(agent.model.parameters(), max_norm=1.0)\n",
    "        agent.optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "      if (epoch+1)%10==0:\n",
    "          print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(values) :.4f}')\n",
    "      steps+=1\n",
    "    agent.save_model(model_dir,f'train_1216_{steps}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "524a13a3-145e-48f4-a9ae-e0695953b16f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model_path = ''\n",
    "agent = ChessAgent(\"white\",device,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfb34ecf-86f0-444d-ba10-c94f9998c3d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stockfish_data/best_dataset_2_167.json', 'stockfish_data/best_dataset_2_168.json', 'stockfish_data/best_dataset_2_169.json', 'stockfish_data/best_dataset_2_170.json', 'stockfish_data/best_dataset_2_171.json', 'stockfish_data/best_dataset_2_172.json', 'stockfish_data/best_dataset_2_173.json', 'stockfish_data/best_dataset_2_174.json', 'stockfish_data/best_dataset_2_175.json', 'stockfish_data/best_dataset_2_176.json', 'stockfish_data/best_dataset_2_177.json', 'stockfish_data/best_dataset_2_178.json', 'stockfish_data/best_dataset_2_179.json', 'stockfish_data/best_dataset_2_180.json', 'stockfish_data/best_dataset_2_181.json', 'stockfish_data/best_dataset_2_182.json', 'stockfish_data/best_dataset_2_183.json', 'stockfish_data/best_dataset_2_184.json', 'stockfish_data/best_dataset_2_185.json', 'stockfish_data/best_dataset_2_186.json', 'stockfish_data/best_dataset_2_187.json', 'stockfish_data/best_dataset_2_188.json', 'stockfish_data/best_dataset_2_189.json', 'stockfish_data/best_dataset_2_190.json', 'stockfish_data/best_dataset_2_191.json', 'stockfish_data/best_dataset_2_192.json', 'stockfish_data/best_dataset_2_193.json', 'stockfish_data/best_dataset_2_194.json', 'stockfish_data/best_dataset_2_195.json', 'stockfish_data/best_dataset_2_196.json', 'stockfish_data/best_dataset_2_197.json', 'stockfish_data/best_dataset_2_198.json', 'stockfish_data/best_dataset_2_199.json', 'stockfish_data/best_dataset_2_200.json', 'stockfish_data/best_dataset_2_201.json', 'stockfish_data/best_dataset_2_202.json', 'stockfish_data/best_dataset_2_203.json', 'stockfish_data/best_dataset_2_204.json', 'stockfish_data/best_dataset_2_205.json', 'stockfish_data/best_dataset_2_206.json', 'stockfish_data/best_dataset_2_207.json', 'stockfish_data/best_dataset_2_208.json', 'stockfish_data/best_dataset_2_209.json', 'stockfish_data/best_dataset_2_210.json', 'stockfish_data/best_dataset_2_211.json', 'stockfish_data/best_dataset_2_212.json', 'stockfish_data/best_dataset_2_213.json', 'stockfish_data/best_dataset_2_214.json', 'stockfish_data/best_dataset_2_215.json', 'stockfish_data/best_dataset_2_216.json', 'stockfish_data/best_dataset_2_217.json', 'stockfish_data/best_dataset_2_218.json', 'stockfish_data/best_dataset_2_219.json', 'stockfish_data/best_dataset_2_220.json', 'stockfish_data/best_dataset_2_221.json', 'stockfish_data/best_dataset_2_222.json', 'stockfish_data/best_dataset_2_223.json', 'stockfish_data/best_dataset_2_224.json']\n",
      "58\n",
      "Training agent white\n",
      "load data from stockfish_data/best_dataset_2_224.json\n",
      "load data from stockfish_data/best_dataset_2_223.json\n",
      "load data from stockfish_data/best_dataset_2_222.json\n",
      "load data from stockfish_data/best_dataset_2_221.json\n",
      "load data from stockfish_data/best_dataset_2_220.json\n",
      "load data from stockfish_data/best_dataset_2_219.json\n",
      "load data from stockfish_data/best_dataset_2_218.json\n",
      "load data from stockfish_data/best_dataset_2_217.json\n",
      "load data from stockfish_data/best_dataset_2_216.json\n",
      "load data from stockfish_data/best_dataset_2_215.json\n",
      "num_data 461\n",
      "Epoch 10/50, Loss: 9.0249\n",
      "Epoch 20/50, Loss: 7.4255\n",
      "Epoch 30/50, Loss: 6.8351\n",
      "Epoch 40/50, Loss: 6.6304\n",
      "Epoch 50/50, Loss: 6.5453\n",
      "Model saved to models/train_1216_50.pt\n",
      "load data from stockfish_data/best_dataset_2_214.json\n",
      "load data from stockfish_data/best_dataset_2_213.json\n",
      "load data from stockfish_data/best_dataset_2_212.json\n",
      "load data from stockfish_data/best_dataset_2_211.json\n",
      "load data from stockfish_data/best_dataset_2_210.json\n",
      "load data from stockfish_data/best_dataset_2_209.json\n",
      "load data from stockfish_data/best_dataset_2_208.json\n",
      "load data from stockfish_data/best_dataset_2_207.json\n",
      "load data from stockfish_data/best_dataset_2_206.json\n",
      "load data from stockfish_data/best_dataset_2_205.json\n",
      "num_data 490\n",
      "Epoch 10/50, Loss: 7.3237\n",
      "Epoch 20/50, Loss: 6.9894\n",
      "Epoch 30/50, Loss: 6.8837\n",
      "Epoch 40/50, Loss: 6.8424\n",
      "Epoch 50/50, Loss: 6.8185\n",
      "Model saved to models/train_1216_100.pt\n",
      "load data from stockfish_data/best_dataset_2_204.json\n",
      "load data from stockfish_data/best_dataset_2_203.json\n",
      "load data from stockfish_data/best_dataset_2_202.json\n",
      "load data from stockfish_data/best_dataset_2_201.json\n",
      "load data from stockfish_data/best_dataset_2_200.json\n",
      "load data from stockfish_data/best_dataset_2_199.json\n",
      "load data from stockfish_data/best_dataset_2_198.json\n",
      "load data from stockfish_data/best_dataset_2_197.json\n",
      "load data from stockfish_data/best_dataset_2_196.json\n",
      "load data from stockfish_data/best_dataset_2_195.json\n",
      "num_data 490\n",
      "Epoch 10/50, Loss: 7.5696\n",
      "Epoch 20/50, Loss: 7.2622\n",
      "Epoch 30/50, Loss: 7.1829\n",
      "Epoch 40/50, Loss: 7.1459\n",
      "Epoch 50/50, Loss: 7.1269\n",
      "Model saved to models/train_1216_150.pt\n",
      "load data from stockfish_data/best_dataset_2_194.json\n",
      "load data from stockfish_data/best_dataset_2_193.json\n",
      "load data from stockfish_data/best_dataset_2_192.json\n",
      "load data from stockfish_data/best_dataset_2_191.json\n",
      "load data from stockfish_data/best_dataset_2_190.json\n",
      "load data from stockfish_data/best_dataset_2_189.json\n",
      "load data from stockfish_data/best_dataset_2_188.json\n",
      "load data from stockfish_data/best_dataset_2_187.json\n",
      "load data from stockfish_data/best_dataset_2_186.json\n",
      "load data from stockfish_data/best_dataset_2_185.json\n",
      "num_data 490\n",
      "Epoch 10/50, Loss: 8.5403\n",
      "Epoch 20/50, Loss: 8.2366\n",
      "Epoch 30/50, Loss: 8.1554\n",
      "Epoch 40/50, Loss: 8.1219\n",
      "Epoch 50/50, Loss: 8.1005\n",
      "Model saved to models/train_1216_200.pt\n",
      "load data from stockfish_data/best_dataset_2_184.json\n",
      "load data from stockfish_data/best_dataset_2_183.json\n",
      "load data from stockfish_data/best_dataset_2_182.json\n",
      "load data from stockfish_data/best_dataset_2_181.json\n",
      "load data from stockfish_data/best_dataset_2_180.json\n",
      "load data from stockfish_data/best_dataset_2_179.json\n",
      "load data from stockfish_data/best_dataset_2_178.json\n",
      "load data from stockfish_data/best_dataset_2_177.json\n",
      "load data from stockfish_data/best_dataset_2_176.json\n",
      "load data from stockfish_data/best_dataset_2_175.json\n",
      "num_data 490\n",
      "Epoch 10/50, Loss: 8.5830\n",
      "Epoch 20/50, Loss: 8.3645\n",
      "Epoch 30/50, Loss: 8.2996\n",
      "Epoch 40/50, Loss: 8.2713\n",
      "Epoch 50/50, Loss: 8.2532\n",
      "Model saved to models/train_1216_250.pt\n",
      "load data from stockfish_data/best_dataset_2_174.json\n",
      "load data from stockfish_data/best_dataset_2_173.json\n",
      "load data from stockfish_data/best_dataset_2_172.json\n",
      "load data from stockfish_data/best_dataset_2_171.json\n",
      "load data from stockfish_data/best_dataset_2_170.json\n",
      "load data from stockfish_data/best_dataset_2_169.json\n",
      "load data from stockfish_data/best_dataset_2_168.json\n",
      "load data from stockfish_data/best_dataset_2_167.json\n",
      "num_data 392\n",
      "Epoch 10/50, Loss: 8.8033\n",
      "Epoch 20/50, Loss: 8.6476\n",
      "Epoch 30/50, Loss: 8.6053\n",
      "Epoch 40/50, Loss: 8.5890\n",
      "Epoch 50/50, Loss: 8.5776\n",
      "Model saved to models/train_1216_300.pt\n"
     ]
    }
   ],
   "source": [
    "train_from_data(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78727e45-dda5-48e2-a1b4-df1995f21215",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
